# api/routes/search.py
# Search endpoint routes with AI fallback when no documents found

import logging
import time
from fastapi import APIRouter, Depends, HTTPException
from typing import Dict

from api.models.schemas import SearchRequest, SearchResponse, ErrorResponse
from api.core.dependencies import get_system_components, SystemComponents

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/search", tags=["search"])


async def generate_ai_fallback_answer(query: str, system_components: Dict) -> str:
    """Use Gemini to answer when no documents found in knowledge base"""
    
    try:
        from llama_index.llms.google_genai import GoogleGenAI
        from config.settings import config
        
        llm = GoogleGenAI(
            model=config.llm.main_model,
            api_key=config.llm.api_key
        )
        
        prompt = f"""You are a helpful AI assistant. The user asked: "{query}"

This question could not be answered from the knowledge base documents. Please provide a helpful, accurate answer based on your general knowledge.

Be concise and direct. If you don't know the answer, say so clearly."""

        response = await llm.acomplete(prompt)
        
        # Add context that this is AI-generated, not from documents
        fallback_answer = f"""**AI Response** (No documents found in knowledge base)

{response.text}

---
*Note: This answer is generated by AI based on general knowledge, not from your document collection. Consider adding relevant documents to your knowledge base for more specific information.*"""
        
        return fallback_answer
        
    except Exception as e:
        logger.error(f"AI fallback answer generation failed: {e}")
        return f"""No relevant documents found for your query: "{query}"

The AI fallback also encountered an error. Please try:
- Rephrasing your query
- Using more specific terms
- Checking if relevant documents exist in the knowledge base"""


async def execute_search(system_components: Dict, query: str):
    """Execute the search pipeline with AI fallback"""
    
    pipeline_start = time.time()
    
    try:
        # STAGE 1: Entity Extraction
        extraction_start = time.time()
        entity_result = system_components["entity_extractor"].extract_entity(query)
        extraction_time = time.time() - extraction_start
        
        logger.info(f"Entity extraction: '{entity_result.entity}' via {entity_result.method}")
        
        # STAGE 2: Query Rewriting  
        rewrite_start = time.time()
        rewrite_result = system_components["query_rewriter"].rewrite_query(
            query, entity_result.entity
        )
        rewrite_time = time.time() - rewrite_start
        
        logger.info(f"Query rewriting: {len(rewrite_result.rewrites)} variants via {rewrite_result.method}")
        
        # STAGE 3: Hybrid Multi-Strategy Retrieval
        retrieval_start = time.time()
        
        # Get required terms for content filtering
        required_terms = []
        if entity_result.entity != query.strip():
            entity_words = [word.lower() for word in entity_result.entity.split() 
                           if len(word) > 2 and word.lower() not in ['the', 'and', 'or']]
            required_terms = entity_words
        
        multi_retrieval_result = await system_components["retriever"].multi_retrieve(
            queries=rewrite_result.rewrites,
            extracted_entity=entity_result.entity,
            required_terms=required_terms
        )
        retrieval_time = time.time() - retrieval_start
        
        logger.info(f"Multi-retrieval: {len(multi_retrieval_result.results)} results via {', '.join(multi_retrieval_result.methods_used)}")
        
        # STAGE 4: Hybrid Results Fusion
        fusion_start = time.time()
        fusion_result = system_components["fusion_engine"].fuse_results(
            all_results=multi_retrieval_result.results,
            original_query=query,
            extracted_entity=entity_result.entity,
            required_terms=required_terms
        )
        fusion_time = time.time() - fusion_start
        
        logger.info(f"Results fusion: {fusion_result.final_count} final results via {fusion_result.fusion_method}")
        
        # STAGE 5: Answer Generation with AI Fallback
        answer_start = time.time()
        
        if len(fusion_result.fused_results) == 0:
            # No documents found - use Gemini AI fallback
            logger.info("No documents found - using AI fallback for general knowledge answer")
            answer = await generate_ai_fallback_answer(query, system_components)
        else:
            # Found documents - generate answer from them
            answer = generate_answer(query, fusion_result.fused_results, entity_result)
        
        answer_time = time.time() - answer_start
        
        total_time = time.time() - pipeline_start
        
        return {
            "entity_result": entity_result,
            "rewrite_result": rewrite_result,
            "fusion_result": fusion_result,
            "answer": answer,
            "performance_metrics": {
                "total_time": total_time,
                "extraction_time": extraction_time,
                "rewrite_time": rewrite_time,
                "retrieval_time": retrieval_time,
                "fusion_time": fusion_time,
                "answer_time": answer_time,
                "pipeline_efficiency": {
                    "extraction_pct": (extraction_time / total_time) * 100,
                    "rewrite_pct": (rewrite_time / total_time) * 100,
                    "retrieval_pct": (retrieval_time / total_time) * 100,
                    "fusion_pct": (fusion_time / total_time) * 100,
                    "answer_pct": (answer_time / total_time) * 100
                }
            }
        }
        
    except Exception as e:
        logger.error(f"Search failed: {e}")
        raise


def generate_answer(query: str, results, entity_result) -> str:
    """Generate answer from search results"""
    
    if not results:
        return f"""No relevant information found for your query: "{query}"

Search Summary:
- Entity extracted: "{entity_result.entity}" (confidence: {entity_result.confidence:.1%})
- Method used: {entity_result.method}
- Search strategy: Hybrid (Vector + Database)

Suggestions:
- Try rephrasing your query
- Use more specific terms
- Check if the information exists in the knowledge base"""

    # Categorize results by quality
    database_results = [r for r in results if "database" in r.source_method]
    vector_results = [r for r in results if ("vector" in r.source_method or "llamaindex" in r.source_method)]
    
    high_quality = [r for r in results if r.similarity_score >= 0.7]
    medium_quality = [r for r in results if 0.4 <= r.similarity_score < 0.7]
    
    # Generate contextual answer
    answer_parts = []
    
    # Header with hybrid search success
    answer_parts.append(f"Found {len(results)} relevant documents for '{entity_result.entity}':")
    
    # Show source distribution
    if database_results and vector_results:
        answer_parts.append(f"\nHybrid Search: {len(database_results)} exact matches + {len(vector_results)} semantic matches")
    elif database_results:
        answer_parts.append(f"\nDatabase Search: {len(database_results)} exact matches found")
    elif vector_results:
        answer_parts.append(f"\nVector Search: {len(vector_results)} semantic matches found")
    
    # High quality results summary
    if high_quality:
        answer_parts.append(f"\n\nPrimary Information ({len(high_quality)} high-confidence documents):")
        for i, result in enumerate(high_quality[:3], 1):
            preview = result.content[:200] + "..." if len(result.content) > 200 else result.content
            source_indicator = "Database" if "database" in result.source_method else "Vector"
            answer_parts.append(f"{i}. [{source_indicator}] {result.filename} (score: {result.similarity_score:.3f})")
            answer_parts.append(f"   {preview}")
    
    # Medium quality results summary  
    if medium_quality and len(high_quality) < 3:
        needed = 3 - len(high_quality)
        answer_parts.append(f"\n\nAdditional Information ({len(medium_quality)} medium-confidence documents):")
        for i, result in enumerate(medium_quality[:needed], len(high_quality) + 1):
            preview = result.content[:150] + "..." if len(result.content) > 150 else result.content
            source_indicator = "Database" if "database" in result.source_method else "Vector"
            answer_parts.append(f"{i}. [{source_indicator}] {result.filename} (score: {result.similarity_score:.3f})")
            answer_parts.append(f"   {preview}")
    
    # Search intelligence summary
    answer_parts.append(f"\n\nSearch Intelligence:")
    answer_parts.append(f"- Entity analysis: {entity_result.method} extraction")
    answer_parts.append(f"- Search approach: Hybrid (Database + Vector)")
    answer_parts.append(f"- Best match confidence: {max(r.similarity_score for r in results):.1%}")
    
    return "\n".join(answer_parts)


@router.post("", response_model=SearchResponse, responses={500: {"model": ErrorResponse}})
async def search(
    request: SearchRequest,
    components: SystemComponents = Depends(get_system_components)
):
    """
    Execute hybrid search with AI fallback.
    
    Pipeline:
    1. Searches knowledge base using hybrid approach (database + vector)
    2. If no documents found, uses Gemini AI to answer from general knowledge
    3. Returns either document-based answer or AI-generated response
    
    - **query**: Search query text (1-1000 characters)
    - **max_results**: Maximum results to return (1-100, default: 20)
    - **similarity_threshold**: Optional similarity threshold (0.0-1.0)
    """
    
    try:
        system_components = components.get_components()
        
        result = await execute_search(system_components, request.query)
        
        # Convert to response model
        from api.models.schemas import (
            EntityResult, QueryRewriteResult, DocumentResult, PerformanceMetrics
        )
        
        return SearchResponse(
            success=True,
            query=request.query,
            entity_result=EntityResult(
                entity=result["entity_result"].entity,
                confidence=result["entity_result"].confidence,
                method=result["entity_result"].method,
                alternatives=result["entity_result"].alternatives,
                metadata=result["entity_result"].metadata
            ),
            rewrite_result=QueryRewriteResult(
                original_query=result["rewrite_result"].original_query,
                rewrites=result["rewrite_result"].rewrites,
                method=result["rewrite_result"].method,
                confidence=result["rewrite_result"].confidence,
                metadata=result["rewrite_result"].metadata
            ),
            results=[
                DocumentResult(
                    filename=doc.filename,
                    content=doc.content,
                    full_content=doc.full_content,
                    similarity_score=doc.similarity_score,
                    source_method=doc.source_method,
                    document_id=doc.document_id,
                    chunk_index=doc.chunk_index,
                    metadata=doc.metadata
                )
                for doc in result["fusion_result"].fused_results[:request.max_results]
            ],
            answer=result["answer"],
            total_results=len(result["fusion_result"].fused_results),
            performance_metrics=PerformanceMetrics(**result["performance_metrics"])
        )
        
    except Exception as e:
        logger.error(f"Search endpoint error: {e}")
        raise HTTPException(status_code=500, detail=str(e))