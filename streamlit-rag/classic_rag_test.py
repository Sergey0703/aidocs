#!/usr/bin/env python3
# ====================================
# ????: classic_rag_test.py (???????????? ?????? ? ?????????? ???????????)
# ?????????? ?????????? ??? ???????????? ???????????? RAG ???????
# ====================================

"""
Classic RAG Test Console - ?????????? ?????? ???????????? RAG ???????
? ?????? ?????????? ??????????? ??? ? intelligent_rag_app.py
"""

import asyncio
import sys
import os
import time
import logging
from pathlib import Path
from typing import Dict, List, Optional
from dotenv import load_dotenv

# ????????? ?????????? ????????? ?? .env ?????
load_dotenv()

# ????????? ???? ??? ???????
current_dir = Path(__file__).parent
backend_dir = current_dir.parent / "backend" if current_dir.name == "streamlit-rag" else current_dir
sys.path.insert(0, str(current_dir))
sys.path.insert(0, str(backend_dir))

# ????????? ???????????
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

class ClassicRAGTester:
    """?????????? ?????? ???????????? RAG ??????? ? ?????? ???????????"""
    
    def __init__(self):
        self.vector_service = None
        self.llm_service = None
        self.stats = {
            "total_queries": 0,
            "successful_queries": 0,
            "avg_search_time": 0.0,
            "avg_llm_time": 0.0,
            "avg_total_time": 0.0
        }
        
        print("?? Classic RAG Test Console (with Content Filtering)")
        print("=" * 50)
    
    async def initialize(self):
        """?????????????? ???????"""
        try:
            print("?? Initializing services...")
            
            # ?????????????? ????????? ?????? - ?????? ?????? ?? ??????? ?????
            try:
                from supabase_vector_service import SupabaseVectorService
            except ImportError as e:
                print(f"? Cannot import SupabaseVectorService: {e}")
                print("   Make sure supabase_vector_service.py is in the same directory")
                return False
            
            # ????????? ?????? ???????? ?????????? ?????????
            connection_string = (
                os.getenv("SUPABASE_CONNECTION_STRING") or 
                os.getenv("DATABASE_URL") or
                os.getenv("POSTGRES_URL")
            )
            
            if not connection_string:
                print("? Database connection string not found!")
                print("   Looking for environment variables:")
                print("   - SUPABASE_CONNECTION_STRING")
                print("   - DATABASE_URL") 
                print("   - POSTGRES_URL")
                print("\n?? Check your .env file or set environment variables")
                return False
            
            self.vector_service = SupabaseVectorService(
                connection_string=connection_string,
                table_name="documents"  # ?????????? ?? ?? ??????? ??? ? rag_indexer
            )
            
            # ?????????????? LLM ?????? - ?????? ?????? ?? ??????? ?????
            try:
                from simple_llm_service import create_simple_llm_service
            except ImportError as e:
                print(f"? Cannot import SimpleLLMService: {e}")
                print("   Make sure simple_llm_service.py is in the same directory")
                return False
            
            ollama_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
            ollama_model = os.getenv("OLLAMA_DEFAULT_MODEL", "llama3.2:3b")
            
            self.llm_service = create_simple_llm_service(
                ollama_url=ollama_url,
                model=ollama_model
            )
            
            # ????????? ?????? ????????
            print("?? Checking services status...")
            
            # ????????? ???? ??????
            try:
                db_stats = await self.vector_service.get_database_stats()
                print(f"   ? Database: {db_stats['total_documents']} documents, {db_stats['unique_files']} files")
            except Exception as e:
                print(f"   ? Database error: {e}")
                return False
            
            # ????????? LLM
            llm_available = await self.llm_service.check_availability()
            if llm_available:
                print(f"   ? LLM: {self.llm_service.model} available at {ollama_url}")
            else:
                print(f"   ?? LLM: {self.llm_service.model} not available at {ollama_url} (will use fallback)")
            
            print("? Initialization complete!")
            return True
            
        except Exception as e:
            print(f"? Initialization failed: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _extract_search_terms(self, query: str) -> List[str]:
        """
        ????????? ????????? ??????? ?? ??????? (?????????? ??????)
        
        Args:
            query: ???????? ??????
            
        Returns:
            ?????? ???????? ???????? ??? ??????
        """
        import re
        
        # ??????? ????????? ?????
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 
                     'of', 'with', 'by', 'about', 'tell', 'me', 'who', 'what', 'where', 
                     'when', 'why', 'how', 'is', 'are', 'was', 'were', 'be', 'been', 
                     'being', 'have', 'has', 'had', 'do', 'does', 'did'}
        
        # ????????? ?????
        words = re.findall(r'\b[A-Za-z]+\b', query.lower())
        
        # ????????? ???????? ?????
        key_terms = [word for word in words if word not in stop_words and len(word) > 2]
        
        # ????????? ???????? ??? ????
        bigrams = []
        query_words = query.split()
        for i in range(len(query_words) - 1):
            bigram = f"{query_words[i]} {query_words[i+1]}"
            if any(char.isupper() for char in bigram):  # ???? ???? ????????? ?????
                bigrams.append(bigram.lower())
        
        return key_terms + bigrams
    
    def _apply_content_filter(self, search_results: List, query_terms: List[str]) -> List:
        """
        ????????? ??????? ?????????? ?????????? ????????? ??? ???????? ???????
        
        Args:
            search_results: ?????????? ?????????? ??????
            query_terms: ??????? ??? ??????
            
        Returns:
            ??????????????? ?????????? ?????????? ??? ????????? ???????
        """
        filtered_results = []
        
        # ?????????? ???????????? ???????
        required_terms = self._get_required_terms(query_terms)
        
        for result in search_results:
            try:
                # ???????? ????? ??? ????????
                content = result.content.lower()
                filename = result.filename.lower()
                full_content = result.full_content.lower()
                
                # ?????????? ???? ????????? ?????
                all_text = f"{content} {filename} {full_content}"
                
                # ????????? ??????? ???? ???????????? ????????
                found_required_terms = []
                missing_terms = []
                
                for term in required_terms:
                    term_lower = term.lower()
                    if term_lower in all_text:
                        found_required_terms.append(term)
                    else:
                        missing_terms.append(term)
                
                # ???????? ? ?????????? ?????? ???? ??????? ??? ???????????? ???????
                if len(missing_terms) == 0:
                    # ??? ????????? ??????? ???????
                    result.search_info["found_terms"] = found_required_terms
                    result.search_info["content_filtered"] = True
                    result.search_info["filter_type"] = "strict_all_terms"
                    filtered_results.append(result)
                    
                    logger.debug(f"? {result.filename}: found ALL required terms {found_required_terms}")
                else:
                    logger.debug(f"? {result.filename}: missing terms {missing_terms}")
                    
            except Exception as e:
                logger.warning(f"Error filtering result {result.filename}: {e}")
                continue
        
        return filtered_results
    
    def _get_required_terms(self, query_terms: List[str]) -> List[str]:
        """
        ?????????? ????? ??????? ???????? ????????????? ??? ??????????
        
        Args:
            query_terms: ??? ??????????? ???????
            
        Returns:
            ?????? ???????????? ????????
        """
        # ??? ???????? ? ??????? ????? ??????? ??? ????? ?????
        name_terms = []
        other_terms = []
        
        for term in query_terms:
            # ????????? ???????? ?? ?????? ?????? (???????? ?????? ??? ????????? ?????)
            if ' ' in term or any(word[0].isupper() for word in term.split() if word):
                # ??? ????????? ??? - ????????? ?? ?????
                name_parts = term.lower().split()
                name_terms.extend(name_parts)
            else:
                # ????????? ?????
                if term.lower() in ['john', 'nolan', 'breeda', 'daly']:
                    # ??? ????? ?????
                    name_terms.append(term.lower())
                else:
                    # ?????? ??????? (????????????)
                    other_terms.append(term.lower())
        
        # ??????? ?????????
        name_terms = list(set(name_terms))
        other_terms = list(set(other_terms))
        
        # ??? ???? ??????? ??? ????? ?????
        if name_terms:
            logger.debug(f"Required name terms: {name_terms}")
            return name_terms
        else:
            # ???? ??? ????, ??????? ???? ?? ???? ??????
            return other_terms[:1] if other_terms else query_terms
    
    async def run_query(self, question: str, language: str = "en") -> Dict:
        """
        ????????? ?????? ???? RAG ??????? ? ?????????? ???????????
        
        Args:
            question: ?????? ????????????
            language: ???? ??????
            
        Returns:
            ?????????? ??????? ? ?????????
        """
        total_start = time.time()
        
        print(f"\n?? Processing: '{question}'")
        print("-" * 50)
        
        try:
            # ????????? ????????? ???????
            search_terms = self._extract_search_terms(question)
            required_terms = self._get_required_terms(search_terms)
            print(f"?? Search terms: {search_terms}")
            print(f"? Required terms (ALL must be present): {required_terms}")
            
            # ?????????? ???????????? ????? ?? ?????? ???????
            dynamic_limit = self._calculate_dynamic_limit(question)
            
            # ???? 1: ????????? ?????
            print("1?? Vector search...")
            search_start = time.time()
            
            # ??????????? ????? ??? ????????? ???????? ?????????? ??????????
            search_limit = dynamic_limit * 2  # ????? ?????? ?????????? ??? ??????????
            
            raw_search_results = await self.vector_service.vector_search(
                query=question,
                limit=search_limit,  # ?????? ??????????
                similarity_threshold=0.2  # ???????? ????? ??? ???????? ??????
            )
            
            print(f"   ?? Raw search: {len(raw_search_results)} candidates")
            
            # ???? 2: ?????????? ??????????
            print("2?? Content filtering...")
            filter_start = time.time()
            
            filtered_results = self._apply_content_filter(raw_search_results, search_terms)
            
            # ???????? ?? ??????? ?????????? ? ????????? ?? ?????????????
            filtered_results = sorted(filtered_results, 
                                    key=lambda x: x.similarity_score, 
                                    reverse=True)[:dynamic_limit]
            
            filter_time = time.time() - filter_start
            search_time = time.time() - search_start
            
            print(f"   ?? After filtering: {len(filtered_results)} documents")
            print(f"   ?? Search completed in {search_time:.3f}s (filter: {filter_time:.3f}s)")
            print(f"   ?? Found {len(filtered_results)} relevant documents (limit: {dynamic_limit})")
            
            # ?????????? ????????? ?????????
            if filtered_results:
                print("   ?? Documents:")
                for i, result in enumerate(filtered_results, 1):
                    similarity = result.similarity_score
                    filename = result.filename
                    match_type = result.search_info["match_type"]
                    found_terms = result.search_info.get("found_terms", [])
                    print(f"      {i}. {filename} (similarity: {similarity:.3f}, {match_type})")
                    print(f"         Contains: {', '.join(found_terms[:3])}")
            else:
                print("   ? No relevant documents found after filtering")
            
            # ???? 3: ????????? ??????
            print(f"\n3?? Generating answer...")
            llm_start = time.time()
            
            # ??????????? ?????????? ??? LLM ???????
            context_docs = []
            for result in filtered_results:
                context_docs.append({
                    'filename': result.filename,
                    'content': result.content,
                    'similarity_score': result.similarity_score
                })
            
            llm_response = await self.llm_service.generate_answer(
                question=question,
                context_docs=context_docs,
                language=language
            )
            
            llm_time = time.time() - llm_start
            total_time = time.time() - total_start
            
            print(f"   ?? LLM completed in {llm_time:.3f}s")
            
            # ????????? ??????????
            self._update_stats(search_time, llm_time, total_time, llm_response.success)
            
            # ??????????
            result = {
                "question": question,
                "language": language,
                "search_terms": search_terms,
                "search_results": filtered_results,
                "llm_response": llm_response,
                "metrics": {
                    "search_time": search_time,
                    "filter_time": filter_time,
                    "llm_time": llm_time,
                    "total_time": total_time,
                    "raw_documents": len(raw_search_results),
                    "documents_found": len(filtered_results),
                    "dynamic_limit": dynamic_limit,
                    "llm_success": llm_response.success,
                    "precision": 1.0 if filtered_results else 0.0  # 100% ???????? ????????? ??????????
                }
            }
            
            return result
            
        except Exception as e:
            total_time = time.time() - total_start
            print(f"? Query failed: {e}")
            
            return {
                "question": question,
                "language": language,
                "error": str(e),
                "metrics": {
                    "total_time": total_time,
                    "documents_found": 0,
                    "llm_success": False
                }
            }
    
    def _update_stats(self, search_time: float, llm_time: float, total_time: float, success: bool):
        """????????? ?????????? ????????"""
        self.stats["total_queries"] += 1
        
        if success:
            self.stats["successful_queries"] += 1
        
        # ????????? ?????????? ???????
        n = self.stats["total_queries"]
        self.stats["avg_search_time"] = (self.stats["avg_search_time"] * (n-1) + search_time) / n
        self.stats["avg_llm_time"] = (self.stats["avg_llm_time"] * (n-1) + llm_time) / n
        self.stats["avg_total_time"] = (self.stats["avg_total_time"] * (n-1) + total_time) / n
    
    def _calculate_dynamic_limit(self, question: str) -> int:
        """
        ????????? ???????????? ????? ?? ?????? ???? ???????
        
        Args:
            question: ?????? ????????????
            
        Returns:
            ??????????? ????? ??? ??????
        """
        question_lower = question.lower()
        
        # ?????????? ??? ???????
        if any(name in question_lower for name in ['john nolan', 'breeda daly', 'specific person']):
            # ??????? ?? ?????????? ????? - ????? ???? ????? ??????????
            return 15
        
        elif any(word in question_lower for word in ['all', 'every', 'complete', 'full']):
            # ??????? ????????? ??????? - ??????????? ?????
            return 20
        
        elif any(word in question_lower for word in ['certifications', 'training', 'courses', 'qualifications']):
            # ??????? ?? ???????? - ????? ???? ????? ??????
            return 12
        
        elif any(word in question_lower for word in ['what', 'explain', 'define', 'describe']):
            # ????? ??????? - ?????????? ?????? ??????????
            return 7
        
        elif len(question.split()) <= 3:
            # ???????? ??????? - ????? ???? ????????
            return 10
        
        else:
            # ??????? ???????
            return 8
    
    def print_result(self, result: Dict):
        """??????? ????????? ??????? ? ???????"""
        print("\n" + "=" * 50)
        print("?? RESULTS")
        print("=" * 50)
        
        if "error" in result:
            print(f"? Error: {result['error']}")
            return
        
        # ????? LLM
        llm_response = result["llm_response"]
        print("?? Answer:")
        print("-" * 20)
        
        if llm_response.success:
            print(llm_response.content)
        else:
            print(f"? LLM Error: {llm_response.error}")
            print("\nFallback response:")
            print(llm_response.content)
        
        # ???????
        metrics = result["metrics"]
        print(f"\n?? Performance:")
        print(f"   Search: {metrics['search_time']:.3f}s")
        if "filter_time" in metrics:
            print(f"   Content Filter: {metrics['filter_time']:.3f}s")
        print(f"   LLM: {metrics['llm_time']:.3f}s")
        print(f"   Total: {metrics['total_time']:.3f}s")
        print(f"   Raw documents: {metrics.get('raw_documents', 0)}")
        print(f"   Filtered documents: {metrics['documents_found']}")
        if "dynamic_limit" in metrics:
            print(f"   Dynamic limit: {metrics['dynamic_limit']}")
        if "precision" in metrics:
            print(f"   Precision: {metrics['precision']:.1%}")
        
        # ????????? ???????
        if "search_terms" in result:
            search_terms = result["search_terms"]
            print(f"\n?? Search Terms: {', '.join(search_terms)}")
        
        # ?????????
        search_results = result.get("search_results", [])
        if search_results:
            print(f"\n?? Sources ({len(search_results)}):")
            for i, doc in enumerate(search_results, 1):
                filename = doc.filename
                similarity = doc.similarity_score
                match_type = doc.search_info["match_type"]
                found_terms = doc.search_info.get("found_terms", [])
                print(f"   {i}. {filename} ({similarity:.3f}, {match_type})")
                if found_terms:
                    print(f"      Found: {', '.join(found_terms[:3])}")
    
    def print_stats(self):
        """??????? ????? ??????????"""
        print("\n" + "=" * 50)
        print("?? SESSION STATISTICS")
        print("=" * 50)
        
        stats = self.stats
        success_rate = (stats["successful_queries"] / stats["total_queries"] * 100) if stats["total_queries"] > 0 else 0
        
        print(f"Total queries: {stats['total_queries']}")
        print(f"Successful: {stats['successful_queries']} ({success_rate:.1f}%)")
        print(f"Average search time: {stats['avg_search_time']:.3f}s")
        print(f"Average LLM time: {stats['avg_llm_time']:.3f}s")
        print(f"Average total time: {stats['avg_total_time']:.3f}s")
        print("?? Content filtering ensures 100% precision")
    
    async def interactive_mode(self):
        """????????????? ????? ??????"""
        print("\n?? Interactive Mode")
        print("Commands:")
        print("  - Type your question to search")
        print("  - 'stats' to show statistics")
        print("  - 'info' to show service info")
        print("  - 'quit' or 'exit' to quit")
        print("-" * 50)
        
        while True:
            try:
                question = input("\n? Your question: ").strip()
                
                if not question:
                    continue
                
                if question.lower() in ['quit', 'exit', 'q']:
                    break
                
                if question.lower() == 'stats':
                    self.print_stats()
                    continue
                
                if question.lower() == 'info':
                    await self.show_service_info()
                    continue
                
                # ?????????? ???? ?? ??????? (??????? ???????????)
                language = "uk" if any(char in question for char in "?????????????????????????????????") else "en"
                
                # ????????? ??????
                result = await self.run_query(question, language)
                self.print_result(result)
                
            except KeyboardInterrupt:
                print("\n\n?? Goodbye!")
                break
            except Exception as e:
                print(f"? Error: {e}")
    
    async def show_service_info(self):
        """?????????? ?????????? ? ????????"""
        print("\n?? Service Information:")
        print("-" * 30)
        
        # ?????????? ? ????????? ???????
        try:
            db_stats = await self.vector_service.get_database_stats()
            print("?? Vector Search Service:")
            print(f"   Database: {db_stats['table_name']}")
            print(f"   Documents: {db_stats['total_documents']}")
            print(f"   Unique files: {db_stats['unique_files']}")
            print(f"   Embedding model: {db_stats['embedding_model']}")
            print(f"   Content filtering: Enabled")
        except Exception as e:
            print(f"?? Vector Search Service: Error - {e}")
        
        # ?????????? ? LLM ???????
        try:
            llm_info = await self.llm_service.get_service_info()
            print(f"\n?? LLM Service:")
            print(f"   Model: {llm_info['model']}")
            print(f"   Available: {llm_info['available']}")
            print(f"   URL: {llm_info['ollama_url']}")
            print(f"   Features: {', '.join(llm_info['features'])}")
        except Exception as e:
            print(f"\n?? LLM Service: Error - {e}")
    
    async def benchmark_mode(self, test_queries: List[str]):
        """????? ????????? ? ????????? ?????????"""
        print(f"\n? Benchmark Mode - {len(test_queries)} queries")
        print("=" * 50)
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n[{i}/{len(test_queries)}] Testing: '{query}'")
            
            result = await self.run_query(query)
            
            # ??????? ????? ???????????
            metrics = result["metrics"]
            llm_response = result.get("llm_response")
            status = "?" if llm_response and llm_response.success else "?"
            
            precision = metrics.get("precision", 0.0)
            raw_docs = metrics.get("raw_documents", 0)
            filtered_docs = metrics["documents_found"]
            
            print(f"   {status} {metrics['total_time']:.3f}s | "
                  f"Raw: {raw_docs} ? Filtered: {filtered_docs} | "
                  f"Precision: {precision:.1%}")
            
            # ????????? ????? ????? ?????????
            await asyncio.sleep(0.5)
        
        print("\n?? Benchmark completed!")
        self.print_stats()

async def main():
    """??????? ???????"""
    # ?????????? ?????????? ? ????????????
    print("?? Configuration:")
    connection_string = (
        os.getenv("SUPABASE_CONNECTION_STRING") or 
        os.getenv("DATABASE_URL") or
        os.getenv("POSTGRES_URL")
    )
    ollama_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434") 
    ollama_model = os.getenv("OLLAMA_DEFAULT_MODEL", "llama3.2:3b")
    
    print(f"   Database: {'? Found' if connection_string else '? Not found'}")
    print(f"   Ollama URL: {ollama_url}")
    print(f"   Ollama Model: {ollama_model}")
    print(f"   Content Filtering: ? Enabled")
    
    # ????????? ??????? ?????????? ?????????
    if not connection_string:
        print("\n? Error: Database connection string not found!")
        print("\n?? Create .env file in the streamlit-rag directory with:")
        print("   SUPABASE_CONNECTION_STRING=your_connection_string")
        print("   # or set DATABASE_URL=your_connection_string")
        print("\n?? Or export environment variable:")
        print("   export SUPABASE_CONNECTION_STRING='your_connection_string'")
        return
    
    # ??????? ? ?????????????? ??????
    tester = ClassicRAGTester()
    
    if not await tester.initialize():
        print("? Failed to initialize services. Exiting.")
        return
    
    # ????????? ????????? ????????? ??????
    if len(sys.argv) > 1:
        if sys.argv[1] == "benchmark":
            # ????? ?????????
            test_queries = [
                "John Nolan",
                "Breeda Daly training"
            ]
            await tester.benchmark_mode(test_queries)
        elif sys.argv[1] == "test":
            # ????????? ????
            query = " ".join(sys.argv[2:]) if len(sys.argv) > 2 else "John Nolan"
            result = await tester.run_query(query)
            tester.print_result(result)
            tester.print_stats()
        else:
            print(f"? Unknown command: {sys.argv[1]}")
            print("Usage: python classic_rag_test.py [benchmark|test 'your question']")
    else:
        # ????????????? ?????
        await tester.interactive_mode()
        tester.print_stats()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\n?? Classic RAG Test interrupted. Goodbye!")
    except Exception as e:
        print(f"\n? Fatal error: {e}")
        sys.exit(1)